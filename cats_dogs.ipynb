{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4ff616f6",
   "metadata": {},
   "source": [
    "# Dogs vs. Cats Prediction Problem\n",
    "#### The main goal of this project is to develop a system that can identify images of cats and dogs. The input image will be analyzed and then the output is predicted. The model that is implemented can be extended to a website or any mobile device as per the need. The main aim here is for the model to learn various distinctive features of cat and dog. Once the training of the model is done it will be able to differentiate images of cat and dog.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e16696c9",
   "metadata": {},
   "source": [
    "## CNN\n",
    "##### Convolutional Neural Network (CNN) is an algorithm taking an image as input then assigning weights and biases to all the aspects of an image and thus differentiates one from the other. Neural networks can be trained by using batches of images, each of them having a label to identify the real nature of the image (cat or dog here). A batch can contain few tenths to hundreds of images. For each and every image, the network prediction is compared with the corresponding existing label, and the distance between network prediction and the truth is evaluated for the whole batch. Then, the network parameters are modified to minimize the distance and thus the prediction capability of the network is increased. The training process continues for every batch similarly.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e26e6f47",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dae2b77d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dense\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "959ed8e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "Model = Sequential()\n",
    "#convolution layer\n",
    "Model.add(Conv2D(32, (3, 3), input_shape = (64, 64, 3), activation = 'relu'))\n",
    "\n",
    "#second convolution layer\n",
    "Model.add(Conv2D(32, (3, 3), activation = 'relu'))\n",
    "Model.add(MaxPooling2D(pool_size =(2, 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "63621bfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "Model.add(Flatten())\n",
    "Model.add(Dense(units = 128, activation = 'relu'))\n",
    "Model.add(Dense(units = 1, activation = 'sigmoid'))\n",
    "Model.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "20c565d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "train_datagen = ImageDataGenerator(rescale = 1./255, \n",
    "                                   shear_range = 0.2, \n",
    "                                   zoom_range = 0.2, \n",
    "                                   horizontal_flip = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "de98a3bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2023 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "test_datagen = ImageDataGenerator(rescale = 1./255, \n",
    "                                  shear_range = 0.2, \n",
    "                                  zoom_range = 0.2, \n",
    "                                  horizontal_flip = True)\n",
    "\n",
    "test_set = test_datagen.flow_from_directory('C:/Users/HP USA/Documents/cat_dog/test_set/test_set', \n",
    "                                              target_size = (64, 64), \n",
    "                                              batch_size =32, \n",
    "                                              class_mode ='binary')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "98371836",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 8005 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "training_set = train_datagen.flow_from_directory('C:/Users/HP USA/Documents/cat_dog/training_set/training_set', \n",
    "                                                   target_size = (64, 64), \n",
    "                                                   batch_size =32, \n",
    "                                                   class_mode ='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f0563d5d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "251/251 [==============================] - 118s 460ms/step - loss: 0.6713 - accuracy: 0.5924 - val_loss: 0.6574 - val_accuracy: 0.6000\n",
      "Epoch 2/10\n",
      "251/251 [==============================] - 118s 471ms/step - loss: 0.5989 - accuracy: 0.6803 - val_loss: 0.5596 - val_accuracy: 0.7031\n",
      "Epoch 3/10\n",
      "251/251 [==============================] - 115s 456ms/step - loss: 0.5442 - accuracy: 0.7209 - val_loss: 0.5468 - val_accuracy: 0.7219\n",
      "Epoch 4/10\n",
      "251/251 [==============================] - 117s 466ms/step - loss: 0.5133 - accuracy: 0.7527 - val_loss: 0.5021 - val_accuracy: 0.7688\n",
      "Epoch 5/10\n",
      "251/251 [==============================] - 127s 507ms/step - loss: 0.4865 - accuracy: 0.7659 - val_loss: 0.4894 - val_accuracy: 0.7656\n",
      "Epoch 6/10\n",
      "251/251 [==============================] - 128s 511ms/step - loss: 0.4669 - accuracy: 0.7786 - val_loss: 0.4659 - val_accuracy: 0.7719\n",
      "Epoch 7/10\n",
      "251/251 [==============================] - 131s 523ms/step - loss: 0.4558 - accuracy: 0.7851 - val_loss: 0.5171 - val_accuracy: 0.7563\n",
      "Epoch 8/10\n",
      "251/251 [==============================] - 125s 498ms/step - loss: 0.4403 - accuracy: 0.7944 - val_loss: 0.4957 - val_accuracy: 0.7563\n",
      "Epoch 9/10\n",
      "251/251 [==============================] - 126s 504ms/step - loss: 0.4215 - accuracy: 0.8011 - val_loss: 0.5126 - val_accuracy: 0.7437\n",
      "Epoch 10/10\n",
      "251/251 [==============================] - 128s 509ms/step - loss: 0.4107 - accuracy: 0.8101 - val_loss: 0.4486 - val_accuracy: 0.8000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x29fe6a87ec8>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Model.fit_generator(training_set,\n",
    "                    epochs =10, \n",
    "                    validation_data = test_set, \n",
    "                    validation_steps = 10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8393b51c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing import image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "75b95842",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cat\n"
     ]
    }
   ],
   "source": [
    "test_image = image.load_img('C:/Users/HP USA/Documents/image_c.PNG', target_size = (64, 64))\n",
    "test_image = image.img_to_array(test_image)\n",
    "test_image = np.expand_dims(test_image, axis = 0)\n",
    "answer = Model.predict(test_image)\n",
    "training_set.class_indices\n",
    "if answer[0][0] == 1:\n",
    "    prediction = 'dog'\n",
    "else:\n",
    "    prediction = 'cat'\n",
    "print(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "07d2af93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dog\n"
     ]
    }
   ],
   "source": [
    "test_image = image.load_img('C:/Users/HP USA/Documents/image_d.PNG', target_size = (64, 64))\n",
    "test_image = image.img_to_array(test_image)\n",
    "test_image = np.expand_dims(test_image, axis = 0)\n",
    "answer = Model.predict(test_image)\n",
    "training_set.class_indices\n",
    "if answer[0][0] == 1:\n",
    "    prediction = 'dog'\n",
    "else:\n",
    "    prediction = 'cat'\n",
    "print(prediction)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
